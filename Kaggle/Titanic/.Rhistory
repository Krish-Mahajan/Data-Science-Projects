dim(InsectSprays)
head(InsectSprays,15)
sA
summary(InsectSprays)[2]
summary(InsectSprays[,2])
sapply(2,InsectSprays,class())
?saaply
?sapply
sapply(InsectSprays,class())
sapply(InsectSprays[,2],class())
skip()
fit<-lm(count~spray,data=InsectSprays)
summary(fit)$coef
est<-summary(fit)$coef[,1]
mean(sA)
mean(sB)
nfit<-lm(count~spray-1)
nfit<-lm(count~spray-1,data=InsectSprays)
summary(nfit)$coef
spray<-relevel(InsectSprays$spray,"C")
spray<-relevel(InsectSprays$spray,\"C\")
spray2 <- relevel(InsectSprays$spray,\"C\")
spray2 <- relevel(InsectSprays$spray,"C")
fit2<-lm(count~spray,data=InsectSprays)
fit2<-lm(count~spray2,data=InsectSprays)
summary(fit2)$coef
mean(sC)
fit$coef[2]-fit$coef[3]/1.6011
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
948
?hunger
head(hunger)
names(hunger)
fit<-lm(numeric~year,data=hunger)
fit<-lm(numeric~Year,data=hunger)
skip()
fit <- lm(hunger$Numeric ~ hunger$Year)
summary(fit)$coef
lmF<-lm(hunger$Numerci~x[hunger$Sex=="Female"])
lmF<-lm(hunger$Numeric~x[hunger$Sex=="Female"])
lmF<-lm(hunger$Numeric~[hunger$Sex=="Female"])
skip()
lmF <- lm(hunger$Numeric[hunger$Sex=="Female"] ~ hunger$Year[hunger$Sex=="Female"])
lmM <-
| lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmM <- lm(Numeric[Sex=="Male"] ~ Year[Sex=="Male"],hunger)
lmBoth<-lm(Numeric~Year+Sex,hunger)
summary(lmBoth)
lmInter<-lm(Numeric~Year+Sex+Sex*Year)
lmInter<-lm(Numeric~Year+Sex+Sex*Year,hunge)
lmInter<-lm(Numeric~Year+Sex+Sex*Year,hunger)
summary(lmInter)
var(resid(lm(price ~ 1, data = diamond))
)
library(UsingR)
data(diamod)
data(diamond)
var(resid(lm(price ~ 1, data = diamond))
)
var(resid(lm(price~carat,data=diamond)))
(992.2482/45643.23)*100
swirl()
fit<-lm(y~x,out2)
plot(fit, which=1)
fitno<-lm(y~x,out2[-1,])
plot(fitno,which=1)
coef(fitno)-coef(fit)
coef(fit)-coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno,
| out2[1,])
resno <- out2[1, "y"] - predict(fitno,out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
skip()
skip()
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
skip()
skip()
head(rstudent(fit))
dy<- predict(fitno, out2)-predict(fit, out2)
sum(dy)^2/(2*sigma^2)
x<-sum(dy^2)/(2*sigma^2)
plot(fit,which=5).
plot(fit,which=5)
rgp1()
rgp2()
head(swiss)
mdl<-lm(fertility~.,data=swiss)
mdl<-lm(Fertility~.,data=swiss)
vif(mdl)
skip()
vif(mdl2)
fullModel <- lm(mpg ~ ., data=mtcars)
summary(fullModel)
library(ggplot2)
data(mtcars)
head(mtcars)
dim(mtcars) #sample data
mtcars$cyl <- as.factor(mtcars$cyl)
mtcars$vs <- as.factor(mtcars$vs)
mtcars$am <- factor(mtcars$am)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
fullModel <- lm(mpg ~ ., data=mtcars)
summary(fullModel) # results hidden
stepModel <- step(fullModel, k=log(nrow(mtcars)))
summary(stepModel)
?mtcars
?step
ggplot(mtcars, aes(x=wt, y=mpg, group=am, color=am, height=3, width=3)) + geom_point() +
scale_colour_discrete(labels=c("Automatic", "Manual")) +
xlab("weight") + ggtitle("Scatter Plot of MPG vs. Weight by Transmission")
amModel<-lm(mpg ~ am, data=mtcars)
summary(amModel)
?mtcars
anova(amModel, stepModel, fullModel, amIntWtModel)
confint(amIntWtModel)
amIntWtModel<-lm(mpg ~ wt + qsec + am + wt:am, data=mtcars)
anova(amModel, stepModel, fullModel, amIntWtModel)
confint(amIntWtModel)
summary(amIntWtModel)$coef
setwd()
getwd()
swirl()
library(swirl)
swirl()
x1c<-simbias(8765)
apply(x1c, 1, mean)
fit<-lm(Fertility~Agriculture,data=swiss)
fit<-lm(Fertility~Agriculture,swiss)
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3<-lm(Fertility~Agriculture+Examination +Education)
fit3<-lm(Fertility~Agriculture+Examination +Education,swiss)
anova(fit1,fit3)
deviance(fit3)
d<-deviance(fit3)/43
n<-deviance(fit1)-deviance(fit3)/2
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d,2,43,lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
View(ravenData)
mdl<_glm(ravenWinum,ravenScore,family="binomial",ravenData)
mdl<-glm(ravenWinum,ravenScore,family="binomial",ravenData)
mdl<-glm(ravenWiNum,ravenScore,family="binomial",ravenData)
skip()
lodds<-predict(mdl,data.frame(ravenScore=c(0, 3, 6)))
exp(lodds)/(1+exp(lodds))
summary(mdl)
confint(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
nxt()
head(fits)
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
confint(mdl, 'date')
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lamda<-mdl$fitted.values[704]
ambda <- mdl$fitted.values[704]
lambda <- mdl$fitted.values[704]
qpois(.95, lambda)
mdl2 <- glm(visits ~ date, poisson,offset=log(visits+1), data=hits)
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits,offset = log(visits + 1))
qpois(.95, mdl2$fitted.values[704])
install.packages(“rattle”, dep=c(“Suggests”))
install.packages(“rattle”)
install.packages("rattle",dep=c("Suggests"))
install.packages("diges")
install.packages("digest")
x<-c(-0.2,-0.9,-0.4,0.6,0.4)
y<-c(0.4,-0.3,-0.3,0.5,1.1)
cor(x,y,method="pearson")
b = cor(y, x) * sd(y) / sd(x)
a = mean(y) - b * mean(x)
plot(x, y)
#lines(x.list, y.list, col="green")
abline(a, b, col="red")
b1 = cor(x, y) * sd(x) / sd(y)
a1 = mean(x) - b * mean(y)
plot(y,x)
#lines(y.list, x.list, col="green")
abline(a1, b1, col="red")
plot(x,y)
abline(a, b, col="blue") #Predicting y from x
abline(0.33/0.84, 1/0.84, col="red") #Predicting x from y
install.packages("AppliedPredictiveModeling")
library(caret)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
View(concrete)
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(mistxures$SuperPlasticizer)
hist(mixtures$SuperPlasticizer)
hist(concrete$SuperPlasticizer)
class(concrete$SuperPlasticizer)
class(mixtures$SuperPlasticizer)
class(SuperPlasticizer)
class(SuperPlasticizer,data=concrete)
head(concrete$SuperPlasticizer)
attach(concrete)
head(concrete$SuperPlasticizer)
head(mixtures$CompressiveStrength)
head(mixtures$SuperPlasticizer)
head(mixtures$Superplasticizer)
hist(mixtures$Superplasticizer)
hist(log(mixtures$Superplasticizer))
hist(log(mixtures$Superplasticizer+1))
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.9)
preObj
preObj1 <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
preObj1
preObj2 <- preProcess(training[, IL_col_idx], method=c("center", "scale", "glm"))
preObj2 <- preProcess(training[, IL_col_idx], method= "glm")
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
new_training <- training[, c(names(training)[IL_col_idx], "diagnosis")]
names(new_training)
IL_col_idx <- grep("^[Ii][Ll].*", names(testing))
new_testing <- testing[, c(names(testing)[IL_col_idx], "diagnosis")]
names(new_testing)
non_pca_model <- train(diagnosis ~ ., data=new_training, method="glm")
# apply the non pca model on the testing set and check the accuracy
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result
pc_training_obj <- preProcess(new_training[, -13], method=c('center', 'scale', 'pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
# compute the model with pca predictors
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
# apply the PCA model on the testing set
pca_result <- confusionMatrix(new_testing[, 13], predict(pca_model, pc_testing_preds))
pca_result
rep(c(0, 3), each = 5)
dataMatrix<-matrix(rnorm(400),nrow=40)
image(1:10,1:40,t(dataMatrix)[,nrow(dataMatrix):1])
heatmap(dataMatrix)
rbinom(1,size=1,prob=0.5)
rbinom(1,size=1,prob=0.5)
rbinom(1,size=1,prob=0.5)
rbinom(1,size=1,prob=0.5)
rbinom(1,size=1,prob=0.5)
rbinom(1,size=1,prob=0.5)
rbinom(1,size=1,prob=0.5)
rep(c(0,3),each=5)
rep(c(0,3),)5
rep(c(0,3),5)
set.seed(678910)
for ( i in 1:40){
coinFlip<-rbinom(1,size=1,prob=0.5)
if coinFlip {
dataMatrix[i,]<-dataMatrix[i,] + rep(c(0,3),each=5)
}
}
set.seed(678910)
for ( i in 1:40){
coinFlip<-rbinom(1,size=1,prob=0.5)
## If coin is heads add a common pattern to that row
if coinFlip {
dataMatrix[i,]<-dataMatrix[i,] + rep(c(0,3),each=5)
}
}
set.seed(678910)
for ( i in 1:40){
coinFlip<-rbinom(1,size=1,prob=0.5)
## If coin is heads add a common pattern to that row
if (coinFlip) {
dataMatrix[i,]<-dataMatrix[i,] + rep(c(0,3),each=5)
}
}
image(1:10,1:40,t(dataMatrix)[,nrow(dataMatrix):1])
heatmap(dataMatrix)
library(dplyr)
hh<-dist(dataMatrix) %>% hclust
?dist
dataMatrixOrdered<-dataMatric[hh$order,]
dataMatrixOrdered<-dataMatrix[hh$order,]
par(mfrow=c(1,3))
par(mfrow=c(1,3))
##Complete Data
image(t(dataMatrixOrdered)[, nrow(dataMatrixOrdered):1])
##Row Means
plot(rowMeans(dataMatrixOrdered), 40:1, , xlab = "Row Mean", ylab = "Row", pch = 19)
## Show the Column means
plot(colMeans(dataMatrixOrdered), xlab = "Column", ylab = "Column Mean", pch = 19)
svd1<-svd(scale(dataMatrixOrdered))
View(svd1)
class(svd1)
svd1[1]
svd1[2]
View(svd1$u[,1])
View(svd1$u[,2])
par(mfrow = c(1, 3))
image(t(dataMatrixOrdered)[, nrow(dataMatrixOrdered):1], main = "Original Data")
plot(svd1$u[, 1], 40:1, , ylab = "Row", xlab = "First left singular vector",
+ pch = 19)
plot(svd1$v[, 1], xlab = "Column", ylab = "First right singular vector", pch = 19)
par(mfrow = c(1, 3))
image(t(dataMatrixOrdered)[, nrow(dataMatrixOrdered):1], main = "Original Data")
plot(svd1$u[, 1], 40:1, , ylab = "Row", xlab = "First left singular vector", pch = 19)
plot(svd1$v[, 1], xlab = "Column", ylab = "First right singular vector", pch = 19)
constantMatrix <- dataMatrixOrdered * 0
View(constantMatrix)
for (i in 1:dim(dataMatrixOrdered)[1]) {
constantMatrix[i, ] <- rep(c(0, 1), each = 5)
}
View(constantMatrix)
data(iris)
library(ggplot2)
names(iris)
View(head(iris))
unique(iris$Species)
table(iris$Species)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
library(caret)
inTrain<-createDataPartition(y=iris$Species,p=0.7,list=FALSE)
taining<-iris[inTrain,]
testing<-iris[-inTrain,]
training<-iris[inTrain,]
testing<-iris[-inTrain,]
dim(training)
dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=Training)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
modFit<-train(Species~.,method="rpart",data=training)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone,package="ElemStatLearn")
ozone<-ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow=10,ncol=155)
dim(ozonw)[1]
dim(ozone)[1]
dim(ozone)
ss <- sample(1:dim(ozone)[1],replace=T)
dim(ss)
View(ss)
View(ozone[ss,])
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
View(ll)
View(ozone)
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret)
)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm")
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
modolive <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modolive, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = F)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA)
)
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
?createFolds
data(oil)
install.packages("kLar")
y
install.packages("klar")
library(caret)
install.packages("klaR")
library(caret)
data(iris)
train_control <- trainControl(method="boot", number=100)
class(train_control)
View(train_control)
head(train_control)
?sample
?matrix
expenses<-c(850,861,1140,931,972)
mean(expenses)
950.8-600
setwd("C:/Users/Krish/Google Drive/Coursera/coursera/Projects/Kaggle/Titanic")
test<-read.csv("./data/test.csv")
train<-read.csv("./data/train.csv")
test$Survived <- NA
combi <- rbind(train, test)
combi$Name<-as.character(combi$Name)
combi$Title <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
combi$Title <- sub(' ', '', combi$Title)
table(combi$Title)
combi$Title[combi$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
combi$Title[combi$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
combi$Title <- factor(combi$Title)
combi$FamilySize <- combi$SibSp + combi$Parch + 1
combi$Surname <- sapply(combi$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
combi$FamilyID <- paste(as.character(combi$FamilySize), combi$Surname, sep="")
combi$FamilyID[combi$FamilySize <= 2] <- 'Small'
table(combi$FamilyID)
famIDs <- data.frame(table(combi$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
combi$FamilyID[combi$FamilyID %in% famIDs$Var1] <- 'Small'
combi$FamilyID <- factor(combi$FamilyID)
train <- combi[1:891,]
test <- combi[892:1309,]
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data=train, method="class")
library(rpart)
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data=train, method="class")
Prediction <- predict(fit, test, type = "class")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "myfirstdtree.csv", row.names = FALSE)
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + FamilySize,
data=combi[!is.na(combi$Age),], method="anova")
summary(combi$Age)
combi$Age[is.na(combi$Age)] <- predict(Agefit, combi[is.na(combi$Age),])
summary(combi$Age)
summary(combi$Embarked)
which(combi$Embarked == '')
combi$Embarked[c(62,830)] = "S"
combi$Embarked <- factor(combi$Embarked)
summary(combi$Fare)
which(is.na(combi$Fare))
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE)
combi$Fare[1044] <- median(combi$Fare, na.rm=TRUE)
combi$FamilyID2 <- combi$FamilyID
combi$FamilyID2 <- as.character(combi$FamilyID2)
combi$FamilyID2[combi$FamilySize <= 3] <- 'Small'
combi$FamilyID2 <- factor(combi$FamilyID2)
set.seed(415)
library(randomForest)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize +
FamilyID2, data=train, importance=TRUE, ntree=2000)
train <- combi[1:891,]
test <- combi[892:1309,]
set.seed(415)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize +
FamilyID2, data=train, importance=TRUE, ntree=2000)
Prediction <- predict(fit, test)
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "firstforest.csv", row.names = FALSE)
install.packages('party')
library(party)
set.seed(415)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title + FamilySize + FamilyID,
data = train, controls=cforest_unbiased(ntree=2000, mtry=3))
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
Prediction <- predict(fit, test, OOB=TRUE, type = "response")
submit <- data.frame(PassengerId = test$PassengerId, Survived = Prediction)
write.csv(submit, file = "2ndforest.csv", row.names = FALSE)
